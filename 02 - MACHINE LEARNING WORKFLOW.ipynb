{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual model creation\n",
    "\n",
    "Install https://orange.biolab.si/\n",
    "\n",
    "## Practice 1. Inspection and data sampling\n",
    "\n",
    "1. Create a new **Data/CSV File Input** and select the file `trilotropicos.csv`. Double click and set column `label` as categorical the rest as numerical\n",
    "2. Create a **Visualize/Scatter Plot** and make a connection from CSV File Input to ScatterPlot. Double click and select `length` and `width` for X/Y axes and select `label` for _color_ and _label_. Set **jitter** to zero.\n",
    "3. Create a **Visualize/Distributions** visualizer and connect the CSV FIle Input to it. Try the following and understand what you see\n",
    "    1.  Select/Unselect _bin numeric variables_\n",
    "    2. Change the precision between _smooth_ and _precise_\n",
    "    3. Group by `label`\n",
    "4. Create a new **Data/DataSampler** and connect the CSV File Input to it. \n",
    "5. Create another **Visualize/Scatter Plot** and connect to it the CSV File Input and the DataSampler. Double click on **each connection** to make sure that\n",
    "    1. CSV File input **data** is connected to the ScatterPlot **data**\n",
    "    2. DataSample **remaining data** is connected to the ScatterPlot **data subset**\n",
    "6. Open (double click) this new scatter plot together with the data sampler, observe what happens when you select and parametrize the different sampling types and click on **Sample Data**\n",
    "7. Try different widgets under **Visualization** and try to understand what you are seeing. Use the help button (lower left)\n",
    "\n",
    "\n",
    "\n",
    "You workflow should look like this\n",
    "\n",
    "![1568728542538](imgs/inspect-data.png)\n",
    "\n",
    "## Practice 2. Create a model\n",
    "\n",
    "\n",
    "\n",
    "1. Create a new **Data/CSV File Input** and select the file `trilotropicos.csv`. Double click and set column `label` as categorical the rest as numerical\n",
    "2. Create a new **Data/Select Columns** and connect it to the CSV File Input. Move the `label` attribute to the **Target** box. With this, we are indicating that this is the attribute we want to predict.\n",
    "3. Continue to build the following workflow. ![1568729684547](imgs/create-model.png)\n",
    "4. Now open **toghether** the tree, predictions and scatter plot\n",
    "5. In the **ScatterPlot** select  `Tree`for _color_ and `label` for _shape_. Select also _show color regions_\n",
    "6. Understand what you are seeing. In particular, the performance metrics reported in the **Predictions** window. Review [this Wikipedia article on Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall). Use the **Confusion matrix** to better understand the performance metrics.\n",
    "7. In the **Tree** change the _Limit the maximal tree depth to_ ranging from 1 to 10, and observe what happes to the **classification boundary** on the scatter plot and the metrics on the predictions widget. Observe that:\n",
    "    1. Lower max depths induce a **simpler** decision tree. Too simple might produce **underfitting**\n",
    "    2. Higher max depths induce a **more complex** decision tree. Too complex might produce **overfitting**\n",
    "8. Connect the **Tree** to a **Visualize/Tree Viewer** and try to understand the tree displayed in terms of the boundaries that you see in the scatter plot\n",
    "\n",
    "## Practice 3. Measuring generalization performance\n",
    "\n",
    "1. Implement the following worlflow using the same data as above ![1568730804462](imgs/generalization-performance-wf.png)\n",
    "2. Open **together** the confusion matrices, the data sampler and the tree configuration\n",
    "3. On the **tree** set _Min number of instances in leaves_ to 1, and experiment changing the max depth from 1 to 10 or beyond.\n",
    "    1. When is TRAIN performance better?\n",
    "    2. When is TEST performance better?\n",
    "    3. When are both performances more similar?\n",
    "4. You can also open both predictions widgets and look at the metrics instead of the confusion matrices.\n",
    "5. Open together the TEST confusion matrix and the Scatter Plot. Select different parts of the confusion matrix to identify where are the misclassifications\n",
    "\n",
    "## Practice 4. Complete machine learning workflow\n",
    "\n",
    "Implement the following workflow. Observe cross validation results at test score and ROC Analysis. Compare performance of all classifiers.\n",
    "\n",
    "![1568776489863](imgs/1568776489863.png)\n",
    "\n",
    "## Practice 5. Regression\n",
    "\n",
    "Implement the following workflow with `cal_housing_full.data` to predict `medianHouseValue` . Use g=0,4 in SVM. \n",
    "\n",
    "![1568777673209](imgs/1568777673209.png)\n",
    "\n",
    "Understand the predictions:\n",
    "\n",
    "- In the scatter plot, display `medianHouseValue` against `randomforest` or `svm` or `tree`.\n",
    "- Leave the scatter plot open and change the parameters of the regressors to observe how classification changes.\n",
    "- Open **Test&Score** and try to interpret the metrics with respect to the plot above.\n",
    "\n",
    "\n",
    "\n",
    "## Practice 6. Other workflows\n",
    "\n",
    "From orange's suggestions [here](https://orange.biolab.si/workflows/) try: Feature Ranking and Cluster Inspection (this is unsupervised!!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
